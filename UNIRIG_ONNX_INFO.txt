================================================================================
                         UniRig ONNX Model Specification
================================================================================

Model: UniRig (VAST-AI-Research)
Repository: https://github.com/VAST-AI-Research/UniRig
License: Apache 2.0
Task: Automatic 3D Model Rigging (Skeleton + Skinning Weights)
Publication: SIGGRAPH 2025

================================================================================
                                  OVERVIEW
================================================================================

UniRig is an automatic 3D rigging framework that uses transformer-based models
to predict skeletal structures and skinning weights for diverse 3D assets.

Two-Stage Architecture:
1. Skeleton Prediction: GPT-like transformer autoregressively predicts a
   topologically valid skeleton using Skeleton Tree Tokenization
2. Skinning Prediction: Bone-Point Cross Attention predicts per-vertex
   skinning weights and bone attributes

Supported Input Formats:
- OBJ, FBX, GLB, VRM meshes

Output:
- Skeleton hierarchy (joint positions, parent indices, bone names)
- Per-vertex skinning weights
- Bone local axes (for FBX export)

================================================================================
                               ONNX COMPONENTS
================================================================================

The export produces four ONNX files:

1. unirig_mesh_encoder.onnx
---------------------------
Purpose: Encode mesh vertices to latent features

INPUTS:
  Name: vertices
  Shape: (batch_size, num_vertices, 3)
  Type: float32
  Description: Mesh vertex positions in object space
  Preprocessing:
    - Center mesh at origin
    - Scale to unit bounding box [-1, 1]

OUTPUTS:
  Name: mesh_features
  Shape: (batch_size, num_tokens, hidden_dim)
  Type: float32
  Description: Encoded mesh features for skeleton/skinning prediction
  Typical: (1, 256, 512)


2. unirig_skeleton_decoder_step.onnx
------------------------------------
Purpose: Single-step autoregressive skeleton token prediction

INPUTS:
  Name: mesh_features
  Shape: (batch_size, num_tokens, hidden_dim)
  Type: float32
  Description: Encoded mesh features

  Name: prev_tokens
  Shape: (batch_size, seq_len)
  Type: int64
  Description: Previously generated skeleton tokens

  Name: prev_positions
  Shape: (batch_size, seq_len, 3)
  Type: float32
  Description: Previously predicted joint positions

OUTPUTS:
  Name: next_token_logits
  Shape: (batch_size, vocab_size)
  Type: float32
  Description: Logits for next token prediction

  Name: next_position
  Shape: (batch_size, 3)
  Type: float32
  Description: Predicted position for next joint


3. unirig_bone_features.onnx
----------------------------
Purpose: Convert skeleton to bone feature vectors

INPUTS:
  Name: joint_positions
  Shape: (batch_size, num_joints, 3)
  Type: float32
  Description: World-space joint positions

  Name: parent_indices
  Shape: (batch_size, num_joints)
  Type: int64
  Description: Parent joint index for each joint (-1 for root)

OUTPUTS:
  Name: bone_features
  Shape: (batch_size, num_joints, hidden_dim)
  Type: float32
  Description: Feature vectors for each bone


4. unirig_skinning_predictor.onnx
---------------------------------
Purpose: Predict per-vertex skinning weights

INPUTS:
  Name: mesh_features
  Shape: (batch_size, num_vertices, hidden_dim)
  Type: float32
  Description: Per-vertex mesh features

  Name: bone_features
  Shape: (batch_size, num_bones, hidden_dim)
  Type: float32
  Description: Per-bone feature vectors

OUTPUTS:
  Name: skinning_weights
  Shape: (batch_size, num_vertices, num_bones)
  Type: float32
  Description: Skinning weights (sum to 1 per vertex)

================================================================================
                            MODEL PARAMETERS
================================================================================

Architecture:
  - Mesh Encoder: 3DShape2VecSet / SAMPart3D-based
  - Skeleton Decoder: OPT-350M-like GPT transformer
  - Skinning Predictor: Bone-Point Cross Attention layers
  - Hidden dimension: 512

Skeleton Token Vocabulary:
  - Joint position tokens (quantized 3D positions)
  - Parent relation tokens
  - Special tokens: <BOS>, <EOS>, <PAD>

Typical Model Sizes:
  - Mesh encoder: ~100 MB
  - Skeleton decoder: ~350 MB (OPT-350M based)
  - Skinning predictor: ~150 MB
  - Total: ~600 MB

Memory Requirements:
  - Inference: ~4 GB VRAM for typical meshes
  - Large meshes (100K+ vertices): ~8 GB VRAM

================================================================================
                              C# USAGE EXAMPLE
================================================================================

using Microsoft.ML.OnnxRuntime;
using Microsoft.ML.OnnxRuntime.Tensors;
using System.Numerics;

public class UniRigInference : IDisposable
{
    private InferenceSession _meshEncoderSession;
    private InferenceSession _skeletonDecoderSession;
    private InferenceSession _boneFeatureSession;
    private InferenceSession _skinningSession;

    private const int HIDDEN_DIM = 512;
    private const int MAX_JOINTS = 256;
    private const int BOS_TOKEN = 0;
    private const int EOS_TOKEN = 1;

    public UniRigInference(string modelDir)
    {
        var options = new SessionOptions();
        try { options.AppendExecutionProvider_CUDA(0); } catch { }

        _meshEncoderSession = new InferenceSession(
            Path.Combine(modelDir, "unirig_mesh_encoder.onnx"), options);
        _skeletonDecoderSession = new InferenceSession(
            Path.Combine(modelDir, "unirig_skeleton_decoder_step.onnx"), options);
        _boneFeatureSession = new InferenceSession(
            Path.Combine(modelDir, "unirig_bone_features.onnx"), options);
        _skinningSession = new InferenceSession(
            Path.Combine(modelDir, "unirig_skinning_predictor.onnx"), options);
    }

    /// <summary>
    /// Full rigging pipeline: Mesh -> Skeleton + Skinning Weights
    /// </summary>
    public RigResult RigMesh(Vector3[] vertices)
    {
        // 1. Normalize and encode mesh
        var normalizedVerts = NormalizeMesh(vertices);
        var meshFeatures = EncodeMesh(normalizedVerts);

        // 2. Generate skeleton autoregressively
        var skeleton = GenerateSkeleton(meshFeatures);

        // 3. Extract bone features
        var boneFeatures = GetBoneFeatures(skeleton.JointPositions, skeleton.ParentIndices);

        // 4. Predict skinning weights
        var skinningWeights = PredictSkinning(meshFeatures, boneFeatures);

        return new RigResult
        {
            JointPositions = skeleton.JointPositions,
            ParentIndices = skeleton.ParentIndices,
            JointNames = skeleton.JointNames,
            SkinningWeights = skinningWeights
        };
    }

    private float[] NormalizeMesh(Vector3[] vertices)
    {
        // Find bounding box
        Vector3 min = new Vector3(float.MaxValue);
        Vector3 max = new Vector3(float.MinValue);

        foreach (var v in vertices)
        {
            min = Vector3.Min(min, v);
            max = Vector3.Max(max, v);
        }

        Vector3 center = (min + max) / 2;
        float scale = Math.Max(Math.Max(max.X - min.X, max.Y - min.Y), max.Z - min.Z) / 2;

        // Normalize to [-1, 1]
        var result = new float[vertices.Length * 3];
        for (int i = 0; i < vertices.Length; i++)
        {
            var v = (vertices[i] - center) / scale;
            result[i * 3] = v.X;
            result[i * 3 + 1] = v.Y;
            result[i * 3 + 2] = v.Z;
        }

        return result;
    }

    private float[] EncodeMesh(float[] vertices)
    {
        int numVerts = vertices.Length / 3;
        var tensor = new DenseTensor<float>(vertices, new[] { 1, numVerts, 3 });

        var inputs = new List<NamedOnnxValue>
        {
            NamedOnnxValue.CreateFromTensor("vertices", tensor)
        };

        using var results = _meshEncoderSession.Run(inputs);
        return results.First().AsTensor<float>().ToArray();
    }

    private SkeletonResult GenerateSkeleton(float[] meshFeatures)
    {
        var tokens = new List<long> { BOS_TOKEN };
        var positions = new List<Vector3> { Vector3.Zero };
        var parentIndices = new List<int> { -1 };
        var jointNames = new List<string> { "root" };

        int meshTokens = meshFeatures.Length / HIDDEN_DIM;

        // Autoregressive generation
        for (int step = 0; step < MAX_JOINTS; step++)
        {
            var inputs = new List<NamedOnnxValue>
            {
                NamedOnnxValue.CreateFromTensor("mesh_features",
                    new DenseTensor<float>(meshFeatures, new[] { 1, meshTokens, HIDDEN_DIM })),
                NamedOnnxValue.CreateFromTensor("prev_tokens",
                    new DenseTensor<long>(tokens.ToArray(), new[] { 1, tokens.Count })),
                NamedOnnxValue.CreateFromTensor("prev_positions",
                    CreatePositionTensor(positions))
            };

            using var results = _skeletonDecoderSession.Run(inputs);

            var logits = results[0].AsTensor<float>().ToArray();
            var nextPos = results[1].AsTensor<float>().ToArray();

            // Sample next token (greedy decoding)
            int nextToken = ArgMax(logits);

            if (nextToken == EOS_TOKEN)
                break;

            tokens.Add(nextToken);
            positions.Add(new Vector3(nextPos[0], nextPos[1], nextPos[2]));

            // Decode token to get parent and name
            (int parent, string name) = DecodeToken(nextToken, positions.Count - 1);
            parentIndices.Add(parent);
            jointNames.Add(name);
        }

        return new SkeletonResult
        {
            JointPositions = positions.Skip(1).ToArray(),  // Skip BOS
            ParentIndices = parentIndices.Skip(1).ToArray(),
            JointNames = jointNames.Skip(1).ToArray()
        };
    }

    private DenseTensor<float> CreatePositionTensor(List<Vector3> positions)
    {
        var data = new float[positions.Count * 3];
        for (int i = 0; i < positions.Count; i++)
        {
            data[i * 3] = positions[i].X;
            data[i * 3 + 1] = positions[i].Y;
            data[i * 3 + 2] = positions[i].Z;
        }
        return new DenseTensor<float>(data, new[] { 1, positions.Count, 3 });
    }

    private int ArgMax(float[] logits)
    {
        int maxIdx = 0;
        float maxVal = logits[0];
        for (int i = 1; i < logits.Length; i++)
        {
            if (logits[i] > maxVal)
            {
                maxVal = logits[i];
                maxIdx = i;
            }
        }
        return maxIdx;
    }

    private (int parent, string name) DecodeToken(int token, int jointIndex)
    {
        // Token decoding depends on UniRig's tokenization scheme
        // Simplified version - actual implementation needs token vocabulary
        return (jointIndex - 1, $"joint_{jointIndex}");
    }

    private float[] GetBoneFeatures(Vector3[] jointPositions, int[] parentIndices)
    {
        int numJoints = jointPositions.Length;

        var posData = new float[numJoints * 3];
        for (int i = 0; i < numJoints; i++)
        {
            posData[i * 3] = jointPositions[i].X;
            posData[i * 3 + 1] = jointPositions[i].Y;
            posData[i * 3 + 2] = jointPositions[i].Z;
        }

        var inputs = new List<NamedOnnxValue>
        {
            NamedOnnxValue.CreateFromTensor("joint_positions",
                new DenseTensor<float>(posData, new[] { 1, numJoints, 3 })),
            NamedOnnxValue.CreateFromTensor("parent_indices",
                new DenseTensor<long>(parentIndices.Select(p => (long)p).ToArray(),
                    new[] { 1, numJoints }))
        };

        using var results = _boneFeatureSession.Run(inputs);
        return results.First().AsTensor<float>().ToArray();
    }

    private float[,] PredictSkinning(float[] meshFeatures, float[] boneFeatures)
    {
        int numVerts = meshFeatures.Length / HIDDEN_DIM;
        int numBones = boneFeatures.Length / HIDDEN_DIM;

        var inputs = new List<NamedOnnxValue>
        {
            NamedOnnxValue.CreateFromTensor("mesh_features",
                new DenseTensor<float>(meshFeatures, new[] { 1, numVerts, HIDDEN_DIM })),
            NamedOnnxValue.CreateFromTensor("bone_features",
                new DenseTensor<float>(boneFeatures, new[] { 1, numBones, HIDDEN_DIM }))
        };

        using var results = _skinningSession.Run(inputs);
        var weights = results.First().AsTensor<float>().ToArray();

        // Reshape to 2D array
        var result = new float[numVerts, numBones];
        for (int v = 0; v < numVerts; v++)
        {
            for (int b = 0; b < numBones; b++)
            {
                result[v, b] = weights[v * numBones + b];
            }
        }

        return result;
    }

    public void Dispose()
    {
        _meshEncoderSession?.Dispose();
        _skeletonDecoderSession?.Dispose();
        _boneFeatureSession?.Dispose();
        _skinningSession?.Dispose();
    }
}

public struct SkeletonResult
{
    public Vector3[] JointPositions;
    public int[] ParentIndices;
    public string[] JointNames;
}

public struct RigResult
{
    public Vector3[] JointPositions;
    public int[] ParentIndices;
    public string[] JointNames;
    public float[,] SkinningWeights;  // [vertex, bone]
}

================================================================================
                           FBX EXPORT FROM C#
================================================================================

To export the rigged mesh to FBX:

public void ExportToFBX(
    Vector3[] vertices,
    int[] triangles,
    RigResult rig,
    string outputPath)
{
    // Use Assimp.NET or FBX SDK for export

    // 1. Create skeleton hierarchy
    var bones = new List<Bone>();
    for (int i = 0; i < rig.JointPositions.Length; i++)
    {
        bones.Add(new Bone
        {
            Name = rig.JointNames[i],
            Position = rig.JointPositions[i],
            ParentIndex = rig.ParentIndices[i]
        });
    }

    // 2. Apply skinning weights (max 4 bones per vertex typically)
    var vertexWeights = new VertexWeight[vertices.Length];
    for (int v = 0; v < vertices.Length; v++)
    {
        // Get top 4 weights
        var topWeights = GetTopKWeights(rig.SkinningWeights, v, 4);
        vertexWeights[v] = new VertexWeight
        {
            BoneIndices = topWeights.Select(w => w.bone).ToArray(),
            Weights = topWeights.Select(w => w.weight).ToArray()
        };
    }

    // 3. Export using your FBX library
    // FbxExporter.Export(outputPath, vertices, triangles, bones, vertexWeights);
}

================================================================================
                        SKELETON TOKEN VOCABULARY
================================================================================

UniRig uses Skeleton Tree Tokenization with:

Position Tokens:
- Quantized 3D positions in normalized space
- Typically 1024 bins per axis = 1024^3 possible positions

Topology Tokens:
- Parent relationship tokens
- Encode which existing joint is the parent

Special Tokens:
- <BOS> (0): Beginning of sequence
- <EOS> (1): End of sequence
- <PAD> (2): Padding

The autoregressive generation follows:
  <BOS> -> joint_1 -> parent_1 -> joint_2 -> parent_2 -> ... -> <EOS>

================================================================================
                             PREPROCESSING NOTES
================================================================================

Mesh Normalization:
  - Center mesh at origin
  - Scale to fit in [-1, 1] bounding box
  - Preserve aspect ratio

Vertex Ordering:
  - Original vertex order is preserved
  - Skinning weights correspond to original vertex indices

Face Information:
  - Faces are used for encoding context
  - Provide face indices if available for better results

Mesh Requirements:
  - Manifold (watertight) meshes preferred
  - Non-manifold meshes may work but with reduced quality
  - Maximum ~100K vertices recommended

================================================================================
                              ERROR HANDLING
================================================================================

1. "Skeleton generation produces no joints"
   - Check mesh normalization
   - Verify input is a valid character/object mesh
   - Try with a simpler mesh first

2. "Skinning weights don't sum to 1"
   - Apply softmax normalization after prediction
   - Filter very small weights (< 0.01)

3. "Skeleton hierarchy invalid"
   - Verify parent indices are valid
   - Root joint should have parent index -1
   - Check for cycles in hierarchy

4. "Memory error during inference"
   - Reduce mesh vertex count (decimate)
   - Use smaller batch size
   - Enable GPU if available

================================================================================
                              VERSION INFO
================================================================================

Export Script Version: 1.0
ONNX Opset: 14
Model: UniRig (SIGGRAPH 2025)
Tested ONNX Runtime: 1.17.1

================================================================================
